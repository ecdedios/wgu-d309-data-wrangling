{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report\n",
    "\n",
    "**Ednalyn C. De Dios  \n",
    "D309, WGU  \n",
    "07/09/2022**\n",
    "\n",
    "\n",
    "## Three Data Sources, Three Methods of Importing\n",
    "\n",
    "The three data sources are listed below. Each of them were imported using different methodologies.\n",
    "\n",
    "1. Enhanced Twitter Data - provided locally and imported using read_csv().\n",
    "1. Image Prediction Data - direct download from the link provided internally.\n",
    "1. Tweets from Twitter API - scraped data from the Twitter API using theuests and tweepy libraries.\n",
    "\n",
    "\n",
    "### Enhanced Twitter Data\n",
    "\n",
    "This is the dataset from WeRateDogs that is provided internally by Udacity. It was imported using panda's read_csv(). It contains basic tweet data from WeRateDogs.\n",
    "\n",
    "\n",
    "### Image Prediction Data\n",
    "\n",
    "This is the data hosted from Udacity's servers. It was imported using the requests library. Generated by a neural network, it contains labeled predictions of objects found in the pictures to include dog breeds. It also has confidence intervals.\n",
    "\n",
    "\n",
    "### Tweets from the Twitter API\n",
    "\n",
    "This is the dataset that is scraped from the Twitter API (V2) using my own developer account. It was queried using the tweepy library and saved locally using json and to_csv(). It contains different stats for the tweets.\n",
    "\n",
    "\n",
    "## Asessing the Data\n",
    "\n",
    "These are just some of the basics issues I've found with the datasets:\n",
    "\n",
    "\n",
    "### Quality issues\n",
    "> 1. \"tweet_id\", \"in_reply_to_status_id\", \"in_reply_to_user_id\", \"retweeted_status_id\", \"retweeted_status_user_id\" should be of data type string or object\n",
    "> 1. \"timestamp\" and \"retweeted_status_timestamp\" should be of data type datetime instead of object\n",
    "> 1. \"source\" in twitter_enhanced_df has irrelevant html characters\n",
    "> 1. nan's are not true nulls (NaN's)\n",
    "> 1. retweet records skew the data so they need to be removed\n",
    "> 1. img_num, p1, p2, p3, p1_conf, p2_conf, p3_conf, p1_dog, p2_dog, p3_dog column names are ambiguous or too vague\n",
    "> 1. p1, p2, p3 values are not standardized - some start with a capital letter while others do not\n",
    "> 1. \"text\" is uncleaned - need to be preprocessed using nlp techniques to garner some valuable insights\n",
    "\n",
    "\n",
    "### Tidiness issues\n",
    "> 1. \"doggo\", \"floofer\", \"pupper\", and \"puppo\" should be combined into one categorical column\n",
    "> 1. all three dataframes should be combined into one master, single source of truth dataframe\n",
    "\n",
    "\n",
    "## Cleaning the Data\n",
    "\n",
    "Structural issues were the major drawbacks in the data so I resolved to deal with them first before taking care of the other issues.\n",
    "\n",
    "\n",
    "### Merging\n",
    "\n",
    "I merged the three dataframes using merge().\n",
    "\n",
    "\n",
    "### Reverse One Hot Encoding\n",
    "\n",
    "I recognized the stages were hot encoded somewhat (not with 0's and 1's) so I had to reverse the encoding using idmax. But first, I had to convert the string to 0's and 1's first.\n",
    "\n",
    "\n",
    "### Data type conversion\n",
    "\n",
    "Converting the datatypes were easy. I wrote a function because I knew that I was going to be doing conversion repeatedly.\n",
    "\n",
    "### Regex\n",
    "\n",
    "I used a few regex patterns to extract relevant information from the columns while shedding some unwanted characters in the strings.\n",
    "\n",
    "### True Nulls\n",
    "\n",
    "I replace pseudo nulls (\"nan\") with true nulls (NaN & NaT)\n",
    "\n",
    "### Removal of Duplicates\n",
    "\n",
    "I removed records that are retweets because they act as duplicates of the original tweets and will skew the data.\n",
    "\n",
    "### Non-descriptive Column Names\n",
    "\n",
    "I renamed columns to be more descriptive to avoid confusion.\n",
    "\n",
    "### Standardization\n",
    "\n",
    "I made sure that all the prediction values are lowercase to aid in analysis later.\n",
    "\n",
    "### NLP - Natural Language Processing\n",
    "\n",
    "I performed basic cleaning of the text using NLTK and regex but the whole prefunctory and more effort is needed to get really good insights with the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
