{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report\n",
    "\n",
    "**Ednalyn C. De Dios  \n",
    "D309, WGU  \n",
    "07/09/2022**\n",
    "\n",
    "\n",
    "## Three Data Sources, Three Methods of Importing\n",
    "\n",
    "The three data sources are listed below. Each of them were imported using different methodologies.\n",
    "\n",
    "1. Enhanced Twitter Data - provided locally and imported using read_csv().\n",
    "1. Image Prediction Data - direct download from the link provided internally.\n",
    "1. Tweets from Twitter API - scraped data from the Twitter API using theuests and tweepy libraries.\n",
    "\n",
    "\n",
    "### Enhanced Twitter Data\n",
    "\n",
    "This is the dataset from WeRateDogs that is provided internally by Udacity. It was imported using panda's read_csv(). It contains basic tweet data from WeRateDogs.\n",
    "\n",
    "\n",
    "### Image Prediction Data\n",
    "\n",
    "This is the data hosted from Udacity's servers. It was imported using the requests library. Generated by a neural network, it contains labeled predictions of objects found in the pictures to include dog breeds. It also has confidence intervals.\n",
    "\n",
    "\n",
    "### Tweets from the Twitter API\n",
    "\n",
    "This is the dataset that is scraped from the Twitter API (V2) using my own developer account. It was queried using the tweepy library and saved locally using json and to_csv(). It contains different stats for the tweets.\n",
    "\n",
    "\n",
    "## Asessing the Data\n",
    "\n",
    "These are just some of the basics issues I've found with the datasets:\n",
    "\n",
    "\n",
    "### Quality issues\n",
    "> 1. \"tweet_id\" should be of data type object or string, not int64\n",
    "> 1. \"in_reply_to_status_id\" data type should be of data type object or string, not float64\n",
    "> 1. \"in_reply_to_user_id\" data type should be of data type object or string, not float 64\n",
    "> 1. \"retweeted_status_id\" data tyoe should be of data type object or string, not float64\n",
    "> 1. \"retweeted_status_user_id\" data type should be of data type object or string, not float64\n",
    "> 1. \"timestamp\" should of data type datetime instead of object\n",
    "> 1. \"retweeted_status_timestamp\" should be of data type datetime instead of object\n",
    "> 1. \"img_num\" in image_predictions_df should be of data type object or string, not int64\n",
    "> 1. \"source\" in twitter_enhanced_df has irrelevant html characters\n",
    "> 1. \"name\", \"doggo\", \"floofer\", \"pupper\", and \"puppo\" in twitter_enhanced_df has None when it should be NaNs. Or, maybe it's better if \"doggo\", \"floofer\", \"pupper\", and \"puppo\" are of boolean data type\n",
    "\n",
    "\n",
    "### Tidiness issues\n",
    "> 1. \"doggo\", \"floofer\", \"pupper\", and \"puppo\" should be combined into one categorical column\n",
    "> 1. all three dataframes should be combined into one master, single source of truth dataframe\n",
    "\n",
    "\n",
    "### Text Data\n",
    "\n",
    "> The data needs to be cleaned and sanitized to produce quality insights using NLP or natural language processing techniques.\n",
    "\n",
    "\n",
    "## Cleaning the Data\n",
    "\n",
    "Structural issues were the major drawbacks in the data so I resolved to deal with them first before taking care of the other issues.\n",
    "\n",
    "\n",
    "### Merging\n",
    "\n",
    "I merged the three dataframes using merge().\n",
    "\n",
    "\n",
    "### Reverse One Hot Encoding\n",
    "\n",
    "I recognized the stages were hot encoded somewhat (not with 0's and 1's) so I had to reverse the encoding using idmax. But first, I had to convert the string to 0's and 1's first.\n",
    "\n",
    "\n",
    "### Data type conversion\n",
    "\n",
    "Converting the datatypes were easy. I wrote a function because I knew that I was going to be doing conversion repeatedly.\n",
    "\n",
    "\n",
    "### * NLP - Natural Language Processing\n",
    "\n",
    "I performed basic cleaning of the text using NLTK and regex but the whole prefunctory and more effort is needed to get really good insights with the text data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
